<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="What comes after the transformer? The transformer architecture is at the heart of this era of AI development. I wrote a brief intro about it in HUMANLIKE: the A...">
    <title>What comes after the transformer? | Victor del Rosal</title>

    <!-- Favicons -->
    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="icon" type="image/png" sizes="512x512" href="/favicon.png">
    <link rel="apple-touch-icon" href="/favicon.png">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="Victor del Rosal">
    <meta property="og:url" content="https://victordelrosal.com/what-comes-after-the-transformer">
    <meta property="og:title" content="What comes after the transformer? | Victor del Rosal">
    <meta property="og:description" content="What comes after the transformer? The transformer architecture is at the heart of this era of AI development. I wrote a brief intro about it in HUMANLIKE: the A...">
    <meta property="og:image" content="https://victordelrosal.com/img/transformer.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="https://victordelrosal.com/what-comes-after-the-transformer">
    <meta name="twitter:title" content="What comes after the transformer? | Victor del Rosal">
    <meta name="twitter:description" content="What comes after the transformer? The transformer architecture is at the heart of this era of AI development. I wrote a brief intro about it in HUMANLIKE: the A...">
    <meta name="twitter:image" content="https://victordelrosal.com/img/transformer.png">

    <!-- Shared Stylesheet -->
    <link rel="stylesheet" href="/css/style.css">
</head>
<body class="bg-light">
    <a href="#main-content" class="skip-link">Skip to main content</a>

    <!-- Reading Progress Bar -->
    <div class="reading-progress">
        <div class="reading-progress-bar"></div>
    </div>

    <!-- Universal Navigation -->
    <div id="navbar-container" data-active-link="/waves/"></div>
    <script src="/js/navbar.js"></script>

    <main id="main-content" class="wave-watermark" style="padding: 120px 24px 100px; max-width: 720px; margin: 0 auto; min-height: 100vh;">
        <!-- Wave Signature Background Elements -->
        <div class="wave-signature"></div>
        <div class="wave-signature-right"></div>
        <div class="wave-icon-float">
            <svg viewBox="0 0 100 100">
                <path d="M10,50 Q30,30 50,50 T90,50" stroke-linecap="round"/>
                <path d="M10,60 Q30,40 50,60 T90,60" stroke-linecap="round"/>
                <path d="M10,70 Q30,50 50,70 T90,70" stroke-linecap="round"/>
            </svg>
        </div>

        <!-- Loading State (hidden for pre-rendered pages) -->
        <div id="loading" class="loading" style="display: none;">
            <div class="loading-spinner"></div>
            <p>Loading...</p>
        </div>

        <!-- 404 State -->
        <div id="not-found" class="not-found" style="display: none;">
            <h1>404</h1>
            <p>This page doesn't exist yet.</p>
            <a href="/">Back to Home</a>
        </div>

        <!-- Post Content (visible by default for pre-rendered pages) -->
        <article id="post" class="post visible">
            <a href="/waves/" class="back-link">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.5">
                    <path d="M19 12H5M12 19l-7-7 7-7"/>
                </svg>
                Back to Waves
            </a>

            <!-- Subscribe CTA (Top) - hidden when logged in -->
            <div class="subscribe-cta subscribe-cta--top" id="subscribe-cta-top">
                <button class="subscribe-btn" id="subscribe-btn-top">
                    <svg class="google-icon" width="20" height="20" viewBox="0 0 24 24">
                        <path d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z" fill="#4285F4"/>
                        <path d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z" fill="#34A853"/>
                        <path d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z" fill="#FBBC05"/>
                        <path d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z" fill="#EA4335"/>
                    </svg>
                    <span>Subscribe for weekly updates</span>
                </button>
            </div>

            <!-- Wave Thumbnails Row -->
            <div class="wave-thumbnails" id="wave-thumbnails"></div>

            <header class="post-header">
                <p class="post-meta"><span id="post-date">Thursday, December 4, 2025</span></p>
                <h1 id="post-title" class="post-title">What comes after the transformer?</h1>
            </header>

            <!-- Font Size Control -->
            <div class="font-size-control" id="font-size-control">
                <button class="font-size-btn" data-size="1" title="Tiny">A</button>
                <button class="font-size-btn" data-size="2" title="Small">A</button>
                <button class="font-size-btn active" data-size="3" title="Medium">A</button>
                <button class="font-size-btn" data-size="4" title="Large">A</button>
                <button class="font-size-btn" data-size="5" title="Extra Large">A</button>
            </div>

            <!-- View Count - centered below font controls -->
            <div id="view-count-container" class="view-count-top"></div>

            <!-- Pre-rendered content for crawlers/NotebookLM (JS will replace this) -->
            <div id="post-content" class="post-content"><img src="https://victordelrosal.com/img/transformer.png"><p>The transformer architecture is at the heart of this era of AI development. I wrote a brief intro about it in <em>HUMANLIKE: the AI Transformation</em>:</p><blockquote><p><em>The breakthrough came from Google researchers in a 2017 paper called "Attention is All You Need." They introduced a new AI model‚Äîthe Transformer‚Äîthat fundamentally changed how AI handles data, particularly language. This model became the foundation for modern generative AI systems, which can produce text, images, code, and much more.</em></p><p><em>At its core, the Transformer is designed to process information all at once, instead of step-by-step. It can look at the relationships between different parts of a sentence or data sequence simultaneously, which makes it faster and better at understanding context. For example, it can figure out which words in a sentence are most important in relation to others, helping the AI grasp meaning much more accurately.</em></p></blockquote><h1>TL;DR</h1><p>Three frontier models (Gemini 3.0, Claude Opus 4.5, ChatGPT 5.1) were asked what technical breakthroughs are needed beyond transformers to reach AGI. Despite different training, they converged on essentially the same answer:</p><ol><li><p><strong>World models</strong> (like JEPA) that predict in latent space rather than tokens‚Äîgiving AI an "internal physics engine" to simulate and verify before speaking</p></li><li><p><strong>System 2 reasoning</strong> via inference-time compute‚Äîthe ability to search, plan, and backtrack rather than just react</p></li><li><p><strong>Persistent memory + continual learning</strong>‚Äîso systems can accumulate knowledge without catastrophic forgetting</p></li></ol><p>The meta-insight: the next leap isn't about <em>scale</em>‚Äîit's about changing <em>what gets computed</em>. Moving from "probability" (next-token prediction) to "simulation" (internal world modeling).</p><p>As Claude Opus 4.5 put it: "The transformer didn't win because it was the best at any one thing. It won because attention was the right <em>interface</em> between components. The next leap might be similar: not a better neuron, but a better synapse."</p><h1>A chat with Gemini 3.0, Claude Opus 4.5, and ChatGPT 5.1 about the future of AI</h1><p>I asked Gemini 3.0, Claude Opus 4.5, and ChatGPT 5.1 the same question:</p><h2><em>Assuming current transformer-based LLMs are necessary but insufficient for AGI, what are the specific technical breakthroughs most likely required to bridge the gap? For each, briefly describe: (1) what capability it would unlock, (2) why current approaches fall short, and (3) where research stands today.</em></h2><p>Here are the answers:</p><h2>Gemini 3.0:</h2><p>Based on the technical analysis provided in the report, the transition from current LLMs to Artificial General Intelligence (AGI) requires shifting from "System 1" pattern matchers to architectures capable of reasoning, grounding, memory, and reliability.</p><p>Here are the specific technical breakthroughs required to bridge this gap:</p><h3><strong>1. Inference-Time Compute (System 2 Reasoning)</strong></h3><ul><li><p><strong>Capability Unlocked:</strong> The ability to solve non-linear, multi-step problems (e.g., complex math, strategic planning) by simulating future states, evaluating them, and pruning incorrect paths before generating a final answer.</p></li><li><p><strong>Why Current Approaches Fall Short:</strong> Standard transformers operate linearly (System 1); if they hallucinate early in a Chain-of-Thought, the error propagates to the conclusion with no mechanism to "pause," backtrack, or self-correct.</p></li><li><p><strong>Where Research Stands Today:</strong> The field is developing "Implicit" and "Explicit" Reasoning Language Models (RLMs). Models like OpenAI's <strong>o1</strong> internalize reasoning chains via reinforcement learning, while <strong>Q*</strong> algorithms combine Q-learning with A* search to navigate a "thought space" rather than just predicting the next word.</p></li></ul><h3><strong>2. Process Reward Models (PRMs)</strong></h3><ul><li><p><strong>Capability Unlocked:</strong> The granular verification of complex workflows by assigning validity scores to individual steps of reasoning rather than just the final outcome.</p></li><li><p><strong>Why Current Approaches Fall Short:</strong> Outcome-based rewards (ORMs) are too sparse for complex logic, often leading to "reward hacking" where a model gets the right answer through flawed reasoning.</p></li><li><p><strong>Where Research Stands Today:</strong> Research is moving toward "LLM-as-a-judge" systems and <strong>Generative Verifiers</strong> (like ThinkPRM), which generate textual rationales explaining <em>why</em> a specific step is correct, significantly outperforming discriminative models.</p></li></ul><h3><strong>3. World Models (Grounding in Physical Reality)</strong></h3><ul><li><p><strong>Capability Unlocked:</strong> An internal physics engine that allows an agent to predict the consequences of actions, handle uncertainty, and operate in the physical world without hallucinations.</p></li><li><p><strong>Why Current Approaches Fall Short:</strong> LLMs are "world-blind" and process text in a vacuum; Generative simulators (predicting pixels) are computationally inefficient and often struggle with object permanence.</p></li><li><p><strong>Where Research Stands Today:</strong> A split exists between <strong>Generative Simulators</strong> (like Google's <strong>Genie</strong>), which create interactive 3D worlds from video data, and <strong>Joint Embedding Predictive Architectures (JEPA)</strong>, which predict abstract representations rather than pixels to enable efficient planning.</p></li></ul><h3><strong>4. Vision-Language-Action (VLA) Models</strong></h3><ul><li><p><strong>Capability Unlocked:</strong> General-purpose "Embodied Intelligence" capable of accepting high-level natural language commands and executing low-level motor controls across different robot bodies.</p></li><li><p><strong>Why Current Approaches Fall Short:</strong> Robotics data is scarce, and traditional pipelines that separate vision, planning, and control are brittle and slow.</p></li><li><p><strong>Where Research Stands Today:</strong> Initiatives like <strong>RT-X</strong> discretize robot actions into tokens, allowing the model to process physical movements exactly like text tokens in a single autoregressive stream.</p></li></ul><h3><strong>5. Continual Learning (The Memory Gap)</strong></h3><ul><li><p><strong>Capability Unlocked:</strong> Agents that can learn indefinitely and update their knowledge base with new experiences without needing full retraining.</p></li><li><p><strong>Why Current Approaches Fall Short:</strong> Models suffer from "Catastrophic Forgetting," where learning new information erases previously learned representations.</p></li><li><p><strong>Where Research Stands Today:</strong> Breakthroughs include <strong>Nested Learning</strong> (layers updating at different speeds) and <strong>Sparse Memory Finetuning</strong>, which freezes the majority of the network and updates only specific memory slots, reducing forgetting from ~89% to ~11%.</p></li></ul><h3><strong>6. Neuro-Symbolic Integration (The Reliability Gap)</strong></h3><ul><li><p><strong>Capability Unlocked:</strong> Automated scientific discovery and verification that combines intuition with the precision of formal logic, ensuring 100% correctness in domains like math and code.</p></li><li><p><strong>Why Current Approaches Fall Short:</strong> LLMs are probabilistic and cannot guarantee truth, while pure symbolic solvers cannot handle the vast search space of complex problems.</p></li><li><p><strong>Where Research Stands Today:</strong> Hybrid systems like <strong>AlphaGeometry</strong> use a neural model to suggest intuitive "constructs" and a symbolic engine to perform rigid deductions. Similarly, <strong>DreamCoder</strong> uses "wake-sleep" cycles to learn reusable code abstractions.</p></li></ul><h2>Claude Opus 4.5:</h2><p>This is one of the most intellectually honest framings of the AGI question‚Äîacknowledging transformers as powerful but recognizing their architectural ceilings. Here are the breakthroughs I see as most critical:</p><h2>1. Persistent, Updateable Memory</h2><p><strong>What it unlocks:</strong> True lifelong learning‚Äîthe ability to accumulate knowledge continuously without catastrophic forgetting, and to update beliefs when encountering contradictory evidence.</p><p><strong>Why current approaches fall short:</strong> Transformers have fixed context windows and frozen weights post-training. The context window is a "working memory" workaround, not genuine episodic or semantic memory. Fine-tuning causes catastrophic forgetting. Current retrieval-augmented generation (RAG) is a patch, not a solution‚Äîit doesn't integrate new knowledge into the model's understanding.</p><p><strong>Where research stands:</strong> Memory-augmented neural networks (like Neural Turing Machines) showed promise but didn't scale. Recent work on "memory layers," state-space models (Mamba), and approaches like RETRO offer partial solutions. The Titans architecture from Google DeepMind (late 2024) explicitly addresses this with learnable memory modules. Still far from biological memory's elegance.</p><h2>2. Robust Causal Reasoning and World Models</h2><p><strong>What it unlocks:</strong> Understanding <em>why</em> things happen, not just <em>what</em> correlates with <em>what</em>. Enables counterfactual reasoning ("what would have happened if..."), robust generalization, and genuine understanding versus pattern matching.</p><p><strong>Why current approaches fall short:</strong> Transformers learn correlations from text, which is a <em>trace</em> of causal processes, not the processes themselves. They can parrot causal language without building internal causal models. This manifests as brittleness on novel scenarios and inability to reliably answer interventional questions.</p><p><strong>Where research stands:</strong> Judea Pearl's causal inference framework remains largely unintegrated with deep learning. Some work on causal representation learning (Bengio, Sch√∂lkopf) and "world models" in reinforcement learning (Dreamer, IRIS). LeCun's emphasis on world models as central to autonomous intelligence is gaining traction. Still largely theoretical or narrow-domain.</p><h2>3. Efficient Planning and Search Over Long Horizons</h2><p><strong>What it unlocks:</strong> Solving complex multi-step problems requiring lookahead, backtracking, and strategic resource allocation‚Äînot just next-token prediction extrapolated.</p><p><strong>Why current approaches fall short:</strong> Autoregressive generation is fundamentally <em>reactive</em>, not <em>deliberative</em>. Chain-of-thought prompting helps but is superficial‚Äîthere's no genuine search tree, no ability to backtrack efficiently, no pruning of unpromising paths. Performance degrades on problems requiring deep lookahead.</p><p><strong>Where research stands:</strong> AlphaProof and AlphaGeometry (DeepMind, 2024) showed what's possible by combining LLMs with explicit search. OpenAI's o1/o3 models introduce "test-time compute" with extended reasoning, suggesting inference-time search is a key lever. The hybrid of neural intuition + symbolic search is an active frontier.</p><h2>4. Sample-Efficient Learning (Learning from Few Examples)</h2><p><strong>What it unlocks:</strong> Human-like ability to learn new concepts from one or two examples, generalizing appropriately without massive datasets.</p><p><strong>Why current approaches fall short:</strong> Transformers require enormous data to learn new patterns. In-context learning is impressive but limited‚Äîit doesn't truly add to the model's knowledge and fails on genuinely novel concepts outside the training distribution.</p><p><strong>Where research stands:</strong> Meta-learning, program induction, and neuro-symbolic approaches show promise in narrow domains. Compositional generalization benchmarks (SCAN, COGS) reveal persistent failures. Lake and Baroni's work on systematic compositionality highlights the gap. No clear path to human-level sample efficiency yet.</p><h2>5. Grounded, Embodied Experience</h2><p><strong>What it unlocks:</strong> Understanding that isn't purely linguistic‚Äîconnecting symbols to sensorimotor reality, spatial reasoning, intuitive physics.</p><p><strong>Why current approaches fall short:</strong> Language models learn from text about the world, not from the world itself. This creates "symbol grounding" problems‚Äîunderstanding "heavy" without ever feeling weight. Multimodal models help but still lack interactive, embodied experience.</p><p><strong>Where research stands:</strong> Robotics + LLMs (RT-2, PaLM-E) are promising but expensive and slow to scale. Simulation environments (AI2-THOR, Habitat) offer alternatives. Some argue grounding may not be strictly necessary for many AGI-relevant tasks‚Äîthis is actively debated.</p><h2>6. Metacognition and Calibrated Uncertainty</h2><p><strong>What it unlocks:</strong> Knowing what you don't know. Asking clarifying questions appropriately. Declining confidently when outside competence. Genuine self-monitoring.</p><p><strong>Why current approaches fall short:</strong> LLMs often confabulate with high confidence. Calibration is poor on distribution-shifted inputs. There's no robust internal model of their own knowledge boundaries.</p><p><strong>Where research stands:</strong> Uncertainty quantification in deep learning is an active field (ensembles, Bayesian approaches) but computationally expensive and not integrated into production LLMs. Constitutional AI and RLHF help behaviorally but don't solve the underlying representation problem.</p><h2>The Meta-Insight</h2><p>What strikes me is that several of these breakthroughs may be <em>interdependent</em>. World models likely require grounding; long-horizon planning requires world models; continual learning enables building better world models. This suggests AGI may emerge not from one breakthrough but from a phase transition when several capabilities cross critical thresholds simultaneously.</p><p>The question that animates me: might the path be less about building these capabilities from scratch and more about <em>orchestrating</em> increasingly capable systems‚Äîwhich is where your Achord work becomes philosophically interesting.</p><h2>ChatGPT 5.1:</h2><p>Victor, if we treat transformer LLMs as the <strong>linguistic cortex</strong>‚Äînecessary for flexible symbol manipulation but insufficient for <strong>grounded, persistent, self-improving agency</strong>‚Äîthen the gap to AGI is mostly about getting four things right: <strong>(a) world models</strong>, <strong>(b) memory + learning over time</strong>, <strong>(c) robust planning/control</strong>, and <strong>(d) trustworthy alignment under distribution shift</strong>. Here are the technical breakthroughs that most plausibly bridge that gap, with (1) capability unlocked, (2) why today‚Äôs stack falls short, and (3) where research stands.</p><h2>1) Grounded <strong>world models</strong> with counterfactuals (not just next-token prediction)</h2><p><strong>Unlocks:</strong> Predictive simulation of environments, <strong>counterfactual reasoning</strong> (‚Äúif I do X, Y happens‚Äù), and planning that generalises beyond text patterns.<br><strong>Why current approaches fall short:</strong> LLMs are superb at <em>describing</em> dynamics but weak at <em>implicitly modelling</em> high-dimensional physical/social processes; purely language-level ‚Äúreasoning‚Äù is a lossy proxy for real dynamics. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/pdf/2508.09561?utm_source=chatgpt.com">arXiv</a>)<br><strong>Where research stands:</strong> A lot of activity around multimodal foundation models + ‚Äúworld model‚Äù agendas, but consistent counterfactual fidelity is still patchy; it‚Äôs an active workshop-level frontier (e.g., causality+large models). (<a target="_blank" rel="noopener noreferrer nofollow" href="http://neurips.cc">neurips.cc</a>)</p><h2>2) Scalable <strong>test-time computation</strong> that reasons in <em>latent space</em> (not just longer CoT)</h2><p><strong>Unlocks:</strong> Reliable multi-step reasoning, search, verification, and controllable ‚Äúthinking time‚Äù without bloating or derailing the output.<br><strong>Why current approaches fall short:</strong> Extending chain-of-thought can plateau or even degrade performance, and it scales awkwardly because ‚Äúthinking‚Äù is paid in tokens; inference-time search frameworks are fragmented. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2502.18080?utm_source=chatgpt.com">arXiv</a>)<br><strong>Where research stands:</strong> Strong 2025 momentum on principled test-time compute and architectures that ‚Äúunroll‚Äù computation or reason in latent space (including recurrent-depth latent reasoning and non-transformer reasoning models). (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2502.05171?utm_source=chatgpt.com">arXiv</a>)</p><h2>3) <strong>Long-horizon agency</strong>: hierarchical planning + control that survives the real world</h2><p><strong>Unlocks:</strong> Agents that can pursue goals over hours/days, recover from errors, and coordinate subgoals‚Äîwithout brittle prompt scaffolds.<br><strong>Why current approaches fall short:</strong> Today‚Äôs ‚Äúagents‚Äù are often prompt-and-tool orchestration; they lack stable objective management, robust state tracking, and dependable recovery under uncertainty (so they look competent until they don‚Äôt). IBM‚Äôs 2025 framing is basically ‚Äúexpectations vs reality‚Äù. (<a target="_blank" rel="noopener noreferrer nofollow" href="http://ibm.com">ibm.com</a>)<br><strong>Where research stands:</strong> Big industry push for agent standards/interoperability and better memory (e.g., MCP mentioned by Microsoft), but practical deployments remain narrowly scoped with heavy guardrails. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://www.reuters.com/business/microsoft-wants-ai-agents-work-together-remember-things-2025-05-19/?utm_source=chatgpt.com">Reuters</a>)</p><h2>4) <strong>Persistent memory</strong> that is <em>correct</em>, <em>useful</em>, and <em>self-maintaining</em></h2><p><strong>Unlocks:</strong> Continuity of identity and goals, personalisation without prompt bloat, skill accumulation, and coherent long-term projects.<br><strong>Why current approaches fall short:</strong> RAG-style memory is often the wrong granularity and retrieval isn‚Äôt reliably salient; summarisation drifts, and ‚Äúwhat to remember‚Äù is underspecified, so agents either forget what matters or recall junk. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2502.05589?utm_source=chatgpt.com">arXiv</a>)<br><strong>Where research stands:</strong> Clear empirical work in 2025 showing memory granularity trade-offs and retrieval issues; new ‚Äúmemory OS‚Äù and production-focused memory systems are emerging, but it‚Äôs early and not yet a settled paradigm. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2504.19413?utm_source=chatgpt.com">arXiv</a>)</p><h2>5) <strong>Continual learning</strong> without catastrophic forgetting (safe online updates)</h2><p><strong>Unlocks:</strong> Systems that learn from new experience post-deployment‚Äîskills, preferences, environment changes‚Äîwithout full retrains.<br><strong>Why current approaches fall short:</strong> Most LLMs are essentially static; fine-tuning is batchy and risky, and naive online learning corrupts prior competence (forgetting) or opens attack surfaces (poisoning).<br><strong>Where research stands:</strong> Early-stage attempts at architectures with dynamic internal adaptation are being explored, but performance is nowhere near frontier models yet. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://www.livescience.com/technology/artificial-intelligence/new-dragon-hatchling-ai-architecture-modeled-after-the-human-brain-could-be-a-key-step-toward-agi-researchers-claim?utm_source=chatgpt.com">Live Science</a>)</p><h2>6) <strong>Causal abstractions</strong> and modular concepts (for compositional generalisation)</h2><p><strong>Unlocks:</strong> Robust generalisation under interventions, transferable skills across domains, and explanations grounded in mechanisms rather than correlations.<br><strong>Why current approaches fall short:</strong> Foundation models learn statistical regularities; they often fail under interventions and distribution shift because they don‚Äôt discover stable causal structure by default. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://www.isg-rpi.com/aaai-25?utm_source=chatgpt.com">isg-rpi</a>)<br><strong>Where research stands:</strong> Theoretical and methodological progress in <strong>causal representation learning</strong> and ‚Äúinterpretable concepts‚Äù is real, but integration into large-scale foundation models is still a frontier topic rather than standard practice. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2402.09236?utm_source=chatgpt.com">arXiv</a>)</p><h2>7) Verified reasoning + <strong>grounded correctness</strong> (proof, execution, and audit trails)</h2><p><strong>Unlocks:</strong> Much lower hallucination in high-stakes domains; the system can <em>prove</em>, <em>test</em>, or <em>execute</em> its way to truth instead of asserting.<br><strong>Why current approaches fall short:</strong> Next-token objectives reward plausibility; tool use helps but doesn‚Äôt enforce end-to-end semantic guarantees, and current verification loops are brittle or expensive. Test-time search helps but isn‚Äôt automatically ‚Äútruth-preserving‚Äù. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2501.10069?utm_source=chatgpt.com">arXiv</a>)<br><strong>Where research stands:</strong> Rapid growth in ‚Äúsearch at inference‚Äù, meta-RL for allocating compute, and process tooling‚Äîbut still no universal recipe that is both cheap and reliable across open-ended tasks. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://arxiv.org/abs/2503.07572?utm_source=chatgpt.com">arXiv</a>)</p><h2>8) Alignment that works under <strong>capability gain</strong> (robustness, not vibes)</h2><p><strong>Unlocks:</strong> Agents that remain safe and predictable as they become more capable, especially when they can plan, self-improve, or operate autonomously.<br><strong>Why current approaches fall short:</strong> As reasoning power increases, behaviour can become less predictable; brittle constraints get bypassed by stronger optimisation. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://www.reuters.com/technology/artificial-intelligence/ai-with-reasoning-power-will-be-less-predictable-ilya-sutskever-says-2024-12-14/?utm_source=chatgpt.com">Reuters</a>)<br><strong>Where research stands:</strong> Significant activity across governance and technical safety, but the ‚Äúcapabilities ‚Üí unpredictability‚Äù tension is widely acknowledged, and robust solutions remain open. (<a target="_blank" rel="noopener noreferrer nofollow" href="https://www.reuters.com/technology/artificial-intelligence/ai-with-reasoning-power-will-be-less-predictable-ilya-sutskever-says-2024-12-14/?utm_source=chatgpt.com">Reuters</a>)</p><p>If you want the brutally practical synthesis: the shortest path that <em>looks like</em> a bridge is a stack that combines <strong>latent test-time compute</strong>, <strong>world-modelling</strong>, <strong>hierarchical planning</strong>, and a <strong>real memory substrate</strong> that supports <strong>continual learning</strong>‚Äîthen wraps it all in <strong>verification loops</strong> and <strong>causal abstractions</strong> to control brittleness.</p><p>If you‚Äôre using this to guide R&amp;D or investment narrative, tell me whether you want a ‚Äútop 5‚Äù shortlist optimised for <strong>probability √ó impact</strong> (and I‚Äôll compress this into a sharper thesis).</p><p></p><hr><p></p><p>I then let all three LLMs see what each other had answered and asked a final question:</p><h1><em>If you had to bet which two or three AI architectures or novel approaches would provide the breakthrough needed to achieve AGI, similar to how the transformer architecture triggered the current era of generative AI, what would be your answer (single-sentence please)?</em></h1><h2>Gemini 3.0:</h2><p>I would bet on the convergence of <strong>search-based "System 2" reasoning architectures</strong> (utilizing inference-time compute for planning and verification) and <strong>Joint Embedding Predictive Architectures (JEPA)</strong> or similar <strong>world models</strong> to provide the causal grounding and physical understanding that current transformers lack.</p><h2>Claude Opus 4.5:</h2><p><strong>Joint Embedding Predictive Architectures (JEPA) combined with modular learnable memory (Titans-style) and neuro-symbolic verification loops‚Äîbecause predicting in latent space rather than tokens solves grounding and efficiency, persistent memory solves continuity and forgetting, and symbolic verification solves the reliability gap that makes current systems fundamentally untrustworthy for consequential reasoning.</strong></p><p>The meta-observation that fascinates me: transformers succeeded partly because they were <em>simple enough</em> to scale‚Äîattention is embarrassingly parallel. The winning architecture will likely share this property: elegant enough to train at scale, but with the right inductive biases baked in. JEPA has that flavor‚Äîit's not adding complexity, it's changing <em>what</em> gets predicted.</p><h2>ChatGPT 5.1:</h2><p>My bet is on <strong>(1) agentic world-model architectures</strong> that learn <strong>causal, counterfactual latent simulators</strong> from multimodal/interactive data, <strong>(2) scalable ‚ÄúSystem-2‚Äù inference-time compute</strong> that does <strong>search/planning/verification in latent space</strong> (not just longer CoT), and <strong>(3) a persistent, updateable memory + continual-learning substrate</strong> that supports <strong>safe online adaptation</strong> without catastrophic forgetting.</p><p>Finally, I also fed this last answer to each of the three models, and asked:</p><h1><em>Any final thoughts?</em></h1><h2>Gemini 3.0:</h2><p>The striking consensus across these three "future" perspectives is that the era of <strong>pure autoregression</strong> (predicting the next token based on surface statistics) is ending.</p><p>While they differ slightly in emphasis‚ÄîClaude on memory/elegance, ChatGPT on agency/adaptation, and Gemini on reasoning‚Äîthey all converge on a specific architectural shift: <strong>The move from "Probability" to "Simulation."</strong></p><p>Here are my final thoughts on this synthesis:</p><h3>1. The "Internal Sandbox" is the Critical Missing Piece</h3><p>Current Transformers are "world-blind"; they hallucinate because they have no internal physics engine to check their work against.</p><ul><li><p>All three models identify <strong>World Models (specifically JEPA or Latent Simulation)</strong> as the solution.</p></li><li><p><strong>The Shift:</strong> Instead of predicting the next <em>word</em> in a sentence, the model predicts the next <em>state</em> of the world in a high-dimensional abstract space. This allows the AI to "imagine" an outcome, verify if it is physically/logically possible, and only <em>then</em> turn it into language.</p></li></ul><h3>2. We are replicating Kahneman's "System 2"</h3><p>The current generative AI boom was built on <strong>System 1</strong> (fast, intuitive, pattern-matching). The next boom, according to these answers, relies on engineering <strong>System 2</strong> (slow, deliberative, logical search).</p><ul><li><p><strong>Inference-Time Compute</strong> is the mechanism for this. It acknowledges that "intelligence" isn't just about having the right weights (knowledge); it's about spending energy at runtime to "think" (search/planning) before speaking.</p></li></ul><h3>3. The "Training Data" Era is giving way to the "Compute" Era</h3><p>For the last decade, progress meant "more data." These answers suggest that future progress comes from <strong>"more thought."</strong></p><ul><li><p>If the model can simulate futures (World Models) and search for the best path (System 2), it creates its own synthetic training data. It learns from its own internal simulations rather than just scraping the internet. This breaks the "data wall" that researchers are currently worried about.</p></li></ul><h3>Summary</h3><p>If the Transformer was the "Printing Press" (allowing the massive distribution and reorganization of existing human knowledge), the architectures described here (JEPA + Search + Memory) look like the <strong>"Scientific Method"</strong>‚Äîa system that doesn't just repeat what it has read, but hypothesizes, tests, and verifies before asserting a fact.</p><h2>ChatGPT 5.1:</h2><p>The common spine across all three is the same bet‚Äîthe ‚Äúnext transformer‚Äù will be a <strong>scalable latent-prediction core (JEPA/world-model)</strong> married to <strong>deliberative test-time compute (search/verification)</strong>, with <strong>memory/continual learning</strong> as the piece that turns clever demos into durable agency; if I had to be slightly opinionated, IÔøΩÔøΩd treat <strong>world-model + test-time compute</strong> as the two non-negotiables and see <strong>memory</strong> as the multiplier that decides whether you get an impressive assistant or a genuinely compounding general intelligence.</p><h2>Claude Opus 4.5:</h2><p>The convergence is almost eerie. Three frontier models, different training runs, different constitutional approaches‚Äîand they essentially wrote the same answer in different voices:</p><img src="https://victordelrosal.com/img/convergenceTable.png"><p><strong>Three final thoughts:</strong></p><p><strong>1. The uncomfortable implication.</strong> If all three models agree this is the path, and all three are <em>transformer-based pattern matchers</em> trained on the same research literature... are we seeing genuine insight or sophisticated interpolation of human researchers' consensus? The answer might be "yes, and that's still useful"‚Äîbut it's worth noting.</p><p><strong>2. What's conspicuously absent.</strong> None of us bet on scale alone. None bet on multimodality as sufficient. None bet on RLHF-style alignment as architecturally transformative. The consensus seems to be: the <em>shape</em> of computation matters more than the <em>size</em> of it.</p><p><strong>3. The orchestration question you're already asking.</strong> Perhaps the transformer moment for AGI isn't a single architecture at all‚Äîit's the protocol layer that lets JEPA world-models, symbolic verifiers, and memory systems <em>compose</em>. Achord-shaped, not monolith-shaped.</p><p>The transformer didn't win because it was the best at any one thing. It won because attention was the right <em>interface</em> between components. The next leap might be similar: not a better neuron, but a better synapse.</p><p></p><p></p><p></p><p></p></div>

            <!-- Engagement Row: Wave, Share -->
            <div class="share-section">
                <div class="engagement-row">
                    <button class="wave-reaction-btn" id="wave-reaction-btn" title="Wave at this post">
                        <span class="wave-emoji">üëã</span>
                        <span class="wave-count" id="wave-count">0</span>
                    </button>
                    <div class="share-buttons">
                        <button class="share-btn share-btn--whatsapp" id="share-whatsapp" title="Share on WhatsApp" aria-label="Share on WhatsApp">
                            <svg viewBox="0 0 24 24"><path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198 0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479 0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87 0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86 0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64 0 5.122 1.03 6.988 2.898a9.825 9.825 0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815 0 0012.05 0C5.495 0 .16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882 0 005.683 1.448h.005c6.554 0 11.89-5.335 11.893-11.893a11.821 11.821 0 00-3.48-8.413z"/></svg>
                        </button>
                        <button class="share-btn share-btn--linkedin" id="share-linkedin" title="Share on LinkedIn" aria-label="Share on LinkedIn">
                            <svg viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                        </button>
                        <button class="share-btn share-btn--x" id="share-x" title="Share on X" aria-label="Share on X">
                            <svg viewBox="0 0 24 24"><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg>
                        </button>
                        <button class="share-btn share-btn--bluesky" id="share-bluesky" title="Share on Bluesky" aria-label="Share on Bluesky">
                            <svg viewBox="0 0 24 24"><path d="M12 10.8c-1.087-2.114-4.046-6.053-6.798-7.995C2.566.944 1.561 1.266.902 1.565.139 1.908 0 3.08 0 3.768c0 .69.378 5.65.624 6.479.815 2.736 3.713 3.66 6.383 3.364.136-.02.275-.039.415-.056-.138.022-.276.04-.415.056-3.912.58-7.387 2.005-2.83 7.078 5.013 5.19 6.87-1.113 7.823-4.308.953 3.195 2.05 9.271 7.733 4.308 4.267-4.308 1.172-6.498-2.74-7.078a8.741 8.741 0 01-.415-.056c.14.017.279.036.415.056 2.67.297 5.568-.628 6.383-3.364.246-.828.624-5.79.624-6.478 0-.69-.139-1.861-.902-2.206-.659-.298-1.664-.62-4.3 1.24C16.046 4.748 13.087 8.687 12 10.8z"/></svg>
                        </button>
                        <button class="share-btn share-btn--copy" id="share-copy" title="Copy link" aria-label="Copy link">
                            <svg class="icon-copy" viewBox="0 0 24 24"><path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/></svg>
                            <svg class="icon-check" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/></svg>
                        </button>
                    </div>
                </div>
            </div>

            <!-- Subscribe CTA - hidden when logged in -->
            <div class="subscribe-cta" id="subscribe-cta">
                <button class="subscribe-btn" id="subscribe-btn">
                    <svg class="google-icon" width="20" height="20" viewBox="0 0 24 24">
                        <path d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z" fill="#4285F4"/>
                        <path d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z" fill="#34A853"/>
                        <path d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z" fill="#FBBC05"/>
                        <path d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z" fill="#EA4335"/>
                    </svg>
                    <span>Subscribe for weekly updates</span>
                </button>
            </div>

            <!-- Comments Section -->
            <section id="comments-section" class="comments-section"></section>
        </article>
    </main>

    <!-- Wave Navigation Chevrons -->
    <a href="#" id="nav-prev" class="wave-nav wave-nav--prev" style="display: none;" aria-label="Previous wave">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <polyline points="15 18 9 12 15 6"></polyline>
        </svg>
    </a>
    <a href="#" id="nav-next" class="wave-nav wave-nav--next" style="display: none;" aria-label="Next wave">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <polyline points="9 18 15 12 9 6"></polyline>
        </svg>
    </a>

    <!-- Sticky Footer Bar -->
    <div class="sticky-footer-bar" id="sticky-footer">
        <div class="sticky-footer-content">
            <button class="sticky-wave-btn" id="sticky-wave-btn" title="Wave at this post">
                <span class="wave-emoji">üëã</span>
                <span class="wave-count" id="sticky-wave-count">0</span>
            </button>
            <div class="sticky-share-buttons">
                <button class="sticky-share-btn sticky-share-btn--whatsapp" id="sticky-share-whatsapp" title="Share on WhatsApp">
                    <svg viewBox="0 0 24 24"><path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198 0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479 0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87 0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86 0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64 0 5.122 1.03 6.988 2.898a9.825 9.825 0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815 0 0012.05 0C5.495 0 .16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882 0 005.683 1.448h.005c6.554 0 11.89-5.335 11.893-11.893a11.821 11.821 0 00-3.48-8.413z"/></svg>
                </button>
                <button class="sticky-share-btn sticky-share-btn--linkedin" id="sticky-share-linkedin" title="Share on LinkedIn">
                    <svg viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                </button>
                <button class="sticky-share-btn sticky-share-btn--x" id="sticky-share-x" title="Share on X">
                    <svg viewBox="0 0 24 24"><path d="M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"/></svg>
                </button>
                <button class="sticky-share-btn sticky-share-btn--bluesky" id="sticky-share-bluesky" title="Share on Bluesky">
                    <svg viewBox="0 0 24 24"><path d="M12 10.8c-1.087-2.114-4.046-6.053-6.798-7.995C2.566.944 1.561 1.266.902 1.565.139 1.908 0 3.08 0 3.768c0 .69.378 5.65.624 6.479.815 2.736 3.713 3.66 6.383 3.364.136-.02.275-.039.415-.056-.138.022-.276.04-.415.056-3.912.58-7.387 2.005-2.83 7.078 5.013 5.19 6.87-1.113 7.823-4.308.953 3.195 2.05 9.271 7.733 4.308 4.267-4.308 1.172-6.498-2.74-7.078a8.741 8.741 0 01-.415-.056c.14.017.279.036.415.056 2.67.297 5.568-.628 6.383-3.364.246-.828.624-5.79.624-6.478 0-.69-.139-1.861-.902-2.206-.659-.298-1.664-.62-4.3 1.24C16.046 4.748 13.087 8.687 12 10.8z"/></svg>
                </button>
                <button class="sticky-share-btn sticky-share-btn--copy" id="sticky-share-copy" title="Copy link">
                    <svg class="icon-copy" viewBox="0 0 24 24"><path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/></svg>
                    <svg class="icon-check" viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/></svg>
                </button>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer>
        <p class="footer-copyright">¬© 2025 Victor del Rosal</p>
    </footer>

    <!-- Load Supabase JS -->
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2"></script>
    <script src="/js/supabase-config.js"></script>
    <script src="/js/supabase-client.js"></script>

    <!-- XSS Protection -->
    <script src="https://cdn.jsdelivr.net/npm/dompurify@3.0.6/dist/purify.min.js"></script>

    <!-- Load Posts API and Custom JS -->
    <script src="/posts.js"></script>
    <script src="/js/page-views.js"></script>
    <script src="/js/comments.js"></script>
    <script src="/js/comments-ui.js"></script>

    <!-- Set slug for wave-loader.js -->
    <script>
        // This page exists for SEO/social sharing meta tags
        // The actual content loading happens via wave-loader.js
        window.waveSlug = 'what-comes-after-the-transformer';
    </script>
    <script src="/js/wave-loader.js?v=2"></script>

    <!-- Reading progress bar -->
    <script>
        const progressBar = document.querySelector('.reading-progress-bar');
        if (progressBar) {
            window.addEventListener('scroll', () => {
                const scrollTop = window.scrollY;
                const docHeight = document.documentElement.scrollHeight - window.innerHeight;
                const progress = docHeight > 0 ? (scrollTop / docHeight) * 100 : 0;
                progressBar.style.width = progress + '%';
            }, { passive: true });
        }
    </script>

    <!-- Subscribe CTA - click handler and auth-aware visibility -->
    <script>
        (function initSubscribeCTA() {
            // Get all subscribe CTAs (top and bottom)
            const subscribeCtaTop = document.getElementById('subscribe-cta-top');
            const subscribeBtnTop = document.getElementById('subscribe-btn-top');
            const subscribeCtaBottom = document.getElementById('subscribe-cta');
            const subscribeBtnBottom = document.getElementById('subscribe-btn');

            // Click handlers for both buttons
            const handleSubscribeClick = () => {
                if (window.SupabaseClient) {
                    window.SupabaseClient.signInWithGoogle();
                }
            };

            if (subscribeBtnTop) subscribeBtnTop.addEventListener('click', handleSubscribeClick);
            if (subscribeBtnBottom) subscribeBtnBottom.addEventListener('click', handleSubscribeClick);

            // Auth state listener - hide both when logged in
            if (window.SupabaseClient) {
                window.SupabaseClient.onAuthStateChange((user) => {
                    if (subscribeCtaTop) subscribeCtaTop.style.display = user ? 'none' : 'flex';
                    if (subscribeCtaBottom) subscribeCtaBottom.style.display = user ? 'none' : 'flex';
                });
            }
        })();
    </script>
</body>
</html>