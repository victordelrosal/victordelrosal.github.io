# Session Log: December 14, 2025

## Summary

Two major implementations completed:
1. **Daily AI News Scan** - Fully automated daily AI news aggregation and publishing
2. **Branded Google OAuth** - Replaced ugly Supabase URL with victordelrosal.com in sign-in flow ($300/year saved)

---

## 1. Daily AI News Scan

### Problem
Need automated daily AI news coverage without manual curation, published transparently as machine-generated content.

### Solution
Built a GitHub Actions workflow that:
- Fetches news from 26 RSS sources at 5:00 AM GMT daily
- Deduplicates by URL and fuzzy title matching
- Synthesizes with Claude Sonnet 4
- Publishes to Supabase → static HTML via build-waves.js

### Architecture

```
5:00 AM GMT
    ↓
GitHub Actions triggers daily-ai-news-scan.yml
    ↓
build-scan.js runs:
    ├── Load sources from sources.json
    ├── Fetch RSS feeds (rss-parser)
    ├── Filter to last 24 hours
    ├── Normalize to unified schema
    ├── Deduplicate (URL + fuzzy title)
    ├── Call Claude Sonnet 4 for synthesis
    └── Insert into Supabase published_posts
    ↓
build-waves.yml runs (every 30 min)
    ↓
Static page live at /daily-ai-news-scan-YYYY-MM-DD/
```

### Files Created/Modified

| File | Purpose |
|------|---------|
| `ai-daily-intel/build-scan.js` | Main orchestration script |
| `ai-daily-intel/sources.json` | 26 RSS sources (Tier 1-4) |
| `ai-daily-intel/prompts.js` | Claude system/user prompts |
| `ai-daily-intel/package.json` | Dependencies |
| `.github/workflows/daily-ai-news-scan.yml` | Scheduled workflow |
| `daily-ai-news-scan-about/index.html` | Transparency page |
| `img/daily-ai-news-scan.png` | Header image |

### Source Tiers

- **Tier 1 (Primary):** OpenAI, Anthropic, DeepMind, Google AI, NVIDIA, Microsoft AI, Meta AI
- **Tier 2 (Research):** arXiv cs.AI, cs.LG
- **Tier 3 (Quality Media):** MIT Tech Review, Wired, The Batch, TechCrunch, VentureBeat, The Verge, Ars Technica
- **Tier 4 (Aggregation):** Google News queries for AI regulation, frontier models, enterprise AI, safety, tools, ChatGPT, agents, coding, startups, LLMs

### Key Features

- **Header image** added to every scan (top of content + card thumbnail)
- **Transparency footer** links to /daily-ai-news-scan-about/
- **Deduplication** via URL matching + 80% fuzzy title similarity
- **Minimum threshold** of 3 items required to publish
- **Dry run mode** with `--dry-run` flag

### URL Pattern
```
https://victordelrosal.com/daily-ai-news-scan-YYYY-MM-DD/
```

### Secrets Required (GitHub)
- `ANTHROPIC_API_KEY`
- `SUPABASE_URL`
- `SUPABASE_ANON_KEY`
- `NEWS_API_KEY` (optional)

### Header Image Configuration

**Image URL:** `https://victordelrosal.com/img/daily-ai-news-scan.png`

**Defined in:** `ai-daily-intel/build-scan.js` line 28:
```javascript
const HEADER_IMAGE_URL = 'https://victordelrosal.com/img/daily-ai-news-scan.png';
```

**Usage:**
1. **In content:** Prepended as `<img>` tag above Executive Summary
2. **In database:** Saved to `image` column for card thumbnails on /waves/

---

## Issue Encountered: Missing Database Column

### Symptom
GitHub Actions workflow "Daily AI News Scan #2" failed with exit code 1.

### Error Message
```
FATAL ERROR: Could not find the 'image' column of 'published_posts' in the schema cache
```

### Root Cause
The code was updated to save header image URL to Supabase, but the `image` column didn't exist.

### Fix Applied

**Step 1: Add Missing Column to Supabase**
```sql
ALTER TABLE published_posts ADD COLUMN image TEXT;
```

**Step 2: Install GitHub CLI**
```bash
brew install gh
gh auth login
```

**Step 3: Re-run Workflow**
```bash
gh workflow run "daily-ai-news-scan.yml" --repo victordelrosal/victordelrosal.github.io
```

**Result:** Workflow completed successfully. Image saved correctly.

---

## Troubleshooting Daily AI News Scan

### Workflow Fails with Database Error
Check if the Supabase table schema matches what the code expects. Common fix: add missing columns.

### No Posts Appearing
1. Check workflow logs in GitHub Actions
2. Verify secrets are configured
3. Check Supabase for any RLS policy issues

### Manual Trigger
```bash
gh workflow run "daily-ai-news-scan.yml" --repo victordelrosal/victordelrosal.github.io
```

Or via GitHub UI: Actions → Daily AI News Scan → Run workflow

---

## 2. Branded Google OAuth

### Problem

During Google sign-in, users saw:
```
"Continue to azzzrjnqgkqwpqnroost.supabase.co"
```

This looked unprofessional and suspicious, undermining trust at signup.

### Rejected Solution

**Supabase Custom Domains** - $25/month ($300/year) just to show a nicer URL.

### Implemented Solution

Use Google Identity Services directly on victordelrosal.com with token exchange to Supabase.

**Result:** Users now see "Continue to victordelrosal.com" - **free**.

### How It Works

```
OLD FLOW (ugly):
User → Supabase → Google → "Continue to azzzrjnqgkqwpqnroost.supabase.co" → Back

NEW FLOW (branded):
User → Google popup on YOUR site → "Continue to victordelrosal.com" → Token exchange with Supabase
```

### Implementation

#### 1. Updated `js/supabase-client.js`

Added Google Client ID:
```javascript
const GOOGLE_CLIENT_ID = '67204010920-ifejjqhm4128lk0gfnlkv3p9cdq7o1tv.apps.googleusercontent.com';
```

Replaced `signInWithGoogle()` to:
- Load Google Identity Services script dynamically
- Use `google.accounts.id.initialize()` and `google.accounts.id.prompt()`
- Exchange ID token with Supabase via `supabase.auth.signInWithIdToken()`

#### 2. Google Cloud Console Configuration

**APIs & Services → Credentials → OAuth 2.0 Client ID:**
- Authorized JavaScript origins: `https://victordelrosal.com`

#### 3. Supabase Configuration

**Authentication → Providers → Google → Client IDs:**
```
677816384233-k0k8vnqvb3dvoksvjr542d4f11414qpk.apps.googleusercontent.com,67204010920-ifejjqhm4128lk0gfnlkv3p9cdq7o1tv.apps.googleusercontent.com
```

**Important:** Comma-separated, NO spaces between Client IDs.

### Result

- ✅ Users see **victordelrosal.com** in Google sign-in
- ✅ No $25/month Supabase custom domain
- ✅ All existing auth, database, storage still work
- ✅ Zero downtime, same Supabase project

### Note: FedCM Migration Warning

Google shows a deprecation warning about FedCM (Federated Credential Management). Current code works fine; this is future migration guidance, not urgent.

---

## Commits Made

1. **Add Daily AI News Scan header image and VdR-circled profile image**
2. **Update Daily AI News Scan header image**
3. **Add header image to Daily AI News Scan posts**
4. **Use Google Sign-In directly for branded OAuth experience**
5. **Add session log documenting Dec 14 work**

---

## Final Status

| Item | Status |
|------|--------|
| Daily AI News Scan | Fully operational (5:00 AM UTC daily) |
| Supabase `image` column | Added |
| Header image in content | Working |
| Card thumbnail on /waves/ | Working |
| Branded Google OAuth | Working |
| Cost savings | ~$264/year |

---

## Lessons Learned

1. **Supabase Custom Domains are expensive** ($25/month) for a cosmetic URL change
2. **Google Identity Services + signInWithIdToken()** is the free alternative for branded OAuth
3. **Supabase must whitelist the Google Client ID** in the provider settings (comma-separated, no spaces)
4. **Transparency in automation** - labeling AI-generated content builds trust
5. **Database schema must match code** - always add columns before deploying code that uses them

---

## Future Considerations

- **FedCM Migration** - Google is transitioning to FedCM; monitor and update when mandatory
- **LinkedIn Distribution** - Could add automated posting at 11:00 AM
- **Email Digest** - Could send daily scan to subscribers
- **Source Performance Tracking** - Monitor which sources provide most value

---

## Cost Analysis

| Item | Monthly | Annual |
|------|---------|--------|
| Supabase Custom Domains (avoided) | $25 | $300 |
| GitHub Actions | Free | Free |
| RSS feeds | Free | Free |
| Claude API (Sonnet 4) | ~$3 | ~$36 |

**Net savings: ~$264/year** by using token exchange instead of custom domain.

---

*Session completed: December 14, 2025*
*AI Assistant: Claude Opus 4.5*
